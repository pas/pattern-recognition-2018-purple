For each set of valdated hyper parameters we used a 4-fold-cross-validation.

The following parameters where used

iterations  | learning rate | hidden layers |
30          | 0.01          | 20            |
30          | 0.01          | 40            |
30          | 0.01          | 60            |
30          | 0.01          | 80            |
30          | 0.1           | 20            |
30          | 0.1           | 40            |
30          | 0.1           | 60            |
30          | 0.1           | 80            |
30          | 0.5           | 20            |
30          | 0.5           | 40            |
30          | 0.5           | 60            |
30          | 0.5           | 80            |
30          | 1             | 20            |
30          | 1             | 40            |
30          | 1             | 60            |
30          | 1             | 80            |

If we have a look at the cross-validation values txt file, we see the accuracy values for the different parameter settings.
We have changed the number of training iterations (30 or 60), the learning rate (0.1, 0.5 or 1) and the number of hidden layers (10, 20, 50, 60 or 80).

What we can observe is, that holding the other parameters fix, an increasement of the learning rate
does lead to a worse accuracy.

We have the best cross-validation accuracy for about 60 hidden layers and learning rate 0.1.
It is 83.42 %.

If we look at the plot for learning rate 0.1 and 60 hidden layer, we can observe that
the accuray of both, the test and the validation set increases rapidly with the first training epochs.
Then the accuracy of the test set is always slightly higher than that of the validation set.

Since the accuracy does slightly decrease from about 40 epochs periods and more, we choose the following parameters
for the accuracy test with the test data set:
learning rate: 0.1
hidden layers: 60
number of epochs: 40
This gives us a accuracy of 0.838.
